{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299467c3",
   "metadata": {},
   "source": [
    "> This notebook is meant to show a prototype for basic sentiment analysis with deep learning. Only the basics of preprocessing and architecture are tested. Test subsets of the data are used here only due to the more managable size as a proof of concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd318293",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb8d86",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf5af2e",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8dbe9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c4193f",
   "metadata": {},
   "source": [
    "##### Set Root Dir as CWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d88d86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Documents\\A_DIGIPEN\\PersonalSVN\\Fall22SVN\\CS374\\Project\\cs374-project\n"
     ]
    }
   ],
   "source": [
    "# Navigate to project root (if not already there)\n",
    "if os.path.split(os.getcwd())[1] != \"cs374-project\":\n",
    "    %cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef923cc",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc72c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b0f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/yelp/reviews/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c9a325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31 s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load dev set (10% of total data) as train\n",
    "train = pd.read_pickle(path + \"train.xz\").iloc[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "821b8fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.88 s\n",
      "Wall time: 3.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load test set (10% of total data) as test\n",
    "test = pd.read_pickle(path + \"test.xz\").iloc[:10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ccc29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2903612</th>\n",
       "      <td>I like Wedding Belles for an odd reason. I set...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050964</th>\n",
       "      <td>We had a great stay here. I felt like we got a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226557</th>\n",
       "      <td>A unique place for sure, not your standard bre...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776083</th>\n",
       "      <td>This will be a short review on service and gri...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227582</th>\n",
       "      <td>Great barbershop. Super friendly staff. They a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757466</th>\n",
       "      <td>Been there twice and twice is two to many. Peo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4215725</th>\n",
       "      <td>I gave you 1 star because that's the minimum y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537655</th>\n",
       "      <td>I drove 3 hours to visit the Christmas Village...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247879</th>\n",
       "      <td>The food and wine/ beer options were awesome b...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397286</th>\n",
       "      <td>My husband and I live in the area and we never...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  stars\n",
       "2903612  I like Wedding Belles for an odd reason. I set...      5\n",
       "5050964  We had a great stay here. I felt like we got a...      5\n",
       "1226557  A unique place for sure, not your standard bre...      3\n",
       "776083   This will be a short review on service and gri...      4\n",
       "227582   Great barbershop. Super friendly staff. They a...      5\n",
       "...                                                    ...    ...\n",
       "6757466  Been there twice and twice is two to many. Peo...      1\n",
       "4215725  I gave you 1 star because that's the minimum y...      1\n",
       "5537655  I drove 3 hours to visit the Christmas Village...      4\n",
       "1247879  The food and wine/ beer options were awesome b...      2\n",
       "1397286  My husband and I live in the area and we never...      2\n",
       "\n",
       "[500000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05965e48",
   "metadata": {},
   "source": [
    "##### Save Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6ae318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reviews stars from 0-4\n",
    "y_train = tf.convert_to_tensor(train[\"stars\"].values - 1)\n",
    "y_test = tf.convert_to_tensor(test[\"stars\"].values - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd8d22",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deebf30d",
   "metadata": {},
   "source": [
    "##### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5230aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires download\n",
    "#   $ python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "775b98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns          Requires   Scores          Retokenizes\n",
      "-   ---------------   --------------   --------   -------------   -----------\n",
      "0   tok2vec           doc.tensor                                  False      \n",
      "                                                                             \n",
      "1   tagger            token.tag                   tag_acc         False      \n",
      "                                                                             \n",
      "2   attribute_ruler                                               False      \n",
      "                                                                             \n",
      "3   lemmatizer        token.lemma                 lemma_acc       False      \n",
      "                                                                             \n",
      "4   ner               doc.ents                    ents_f          False      \n",
      "                      token.ent_iob               ents_p                     \n",
      "                      token.ent_type              ents_r                     \n",
      "                                                  ents_per_type              \n",
      "\n",
      "✔ No problems found.\n",
      "{'summary': {'tok2vec': {'assigns': ['doc.tensor'], 'requires': [], 'scores': [], 'retokenizes': False}, 'tagger': {'assigns': ['token.tag'], 'requires': [], 'scores': ['tag_acc'], 'retokenizes': False}, 'attribute_ruler': {'assigns': [], 'requires': [], 'scores': [], 'retokenizes': False}, 'lemmatizer': {'assigns': ['token.lemma'], 'requires': [], 'scores': ['lemma_acc'], 'retokenizes': False}, 'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'], 'requires': [], 'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'], 'retokenizes': False}}, 'problems': {'tok2vec': [], 'tagger': [], 'attribute_ruler': [], 'lemmatizer': [], 'ner': []}, 'attrs': {'doc.ents': {'assigns': ['ner'], 'requires': []}, 'token.tag': {'assigns': ['tagger'], 'requires': []}, 'doc.tensor': {'assigns': ['tok2vec'], 'requires': []}, 'token.ent_type': {'assigns': ['ner'], 'requires': []}, 'token.lemma': {'assigns': ['lemmatizer'], 'requires': []}, 'token.ent_iob': {'assigns': ['ner'], 'requires': []}}}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.analyze_pipes(pretty=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f8b5e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great prices and a fabulous team to help with all your fabric needs! I've especially enjoyed working with the owner Kathy! Beautiful cushions, valances, drapes, and pillows!\n"
     ]
    }
   ],
   "source": [
    "i = 9\n",
    "\n",
    "# Get a single sentence as an example\n",
    "example = [test[\"text\"].iloc[i]]\n",
    "\n",
    "# Create a spacy doc with the example\n",
    "example_doc = list(nlp.pipe(example))[0]\n",
    "print(example_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e5560af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Great][prices][and][a][fabulous][team][to][help][with][all][your][fabric][needs][!][I]['ve][especially][enjoyed][working][with][the][owner][Kathy][!][Beautiful][cushions][,][valances][,][drapes][,][and][pillows][!]"
     ]
    }
   ],
   "source": [
    "# Tokenization example\n",
    "for token in example_doc:\n",
    "    print(\"[\" + token.text + \"]\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e8c6ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Great great ADJ JJ Xxxxx True False ][ prices price NOUN NNS xxxx True False ][ and and CCONJ CC xxx True True ][ a a DET DT x True True ][ fabulous fabulous ADJ JJ xxxx True False ][ team team NOUN NN xxxx True False ][ to to PART TO xx True True ][ help help VERB VB xxxx True False ][ with with ADP IN xxxx True True ][ all all DET DT xxx True True ][ your your PRON PRP$ xxxx True True ][ fabric fabric NOUN NN xxxx True False ][ needs need NOUN NNS xxxx True False ][ ! ! PUNCT . ! False False ][ I I PRON PRP X True True ][ 've 've AUX VBP 'xx False True ][ especially especially ADV RB xxxx True False ][ enjoyed enjoy VERB VBN xxxx True False ][ working work VERB VBG xxxx True False ][ with with ADP IN xxxx True True ][ the the DET DT xxx True True ][ owner owner NOUN NN xxxx True False ][ Kathy Kathy PROPN NNP Xxxxx True False ][ ! ! PUNCT . ! False False ][ Beautiful beautiful ADJ JJ Xxxxx True False ][ cushions cushion NOUN NNS xxxx True False ][ , , PUNCT , , False False ][ valances valance NOUN NNS xxxx True False ][ , , PUNCT , , False False ][ drapes drape NOUN NNS xxxx True False ][ , , PUNCT , , False False ][ and and CCONJ CC xxx True True ][ pillows pillow NOUN NNS xxxx True False ][ ! ! PUNCT . ! False False ]"
     ]
    }
   ],
   "source": [
    "for token in example_doc:\n",
    "    # Print text, simple POS, detailed POS, shape, whether alphabetical, whether stopword\n",
    "    print(\"[\", token.text, token.lemma_, token.pos_, token.tag_,\n",
    "          token.shape_, token.is_alpha, token.is_stop, \"]\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63198971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kathy 116 121 PERSON\n"
     ]
    }
   ],
   "source": [
    "# Named entity recognition\n",
    "for ent in example_doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6646a6bd",
   "metadata": {},
   "source": [
    "##### Perform Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af417ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(doc):\n",
    "    \"\"\"Preprocesses a spacy Doc.\n",
    "    \n",
    "    Currently tokenizes, lemmatizes, and removes stopwords\n",
    "    \"\"\"\n",
    "    output = list()\n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.is_alpha:\n",
    "            output.append(str(token.lemma_))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "311f594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_normalize(docs, batch_size=1_000, n_processes=1):\n",
    "    \"\"\"Applies preprocessing steps to iterable of spacy Docs.\"\"\"\n",
    "    results = []\n",
    "    for doc in nlp.pipe(docs, n_process=n_processes):\n",
    "        results.append(normalize(doc))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46ca8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 56s\n",
      "Wall time: 14min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Lowercase\n",
    "X_train = train[\"text\"].str.lower()\n",
    "X_test = test[\"text\"].str.lower()\n",
    "\n",
    "# Set multiprocessing params\n",
    "batch_size = 2000\n",
    "n_processes = 4\n",
    "\n",
    "# Preprocess reviews\n",
    "X_train = apply_normalize(X_train, batch_size=batch_size, n_processes=n_processes)\n",
    "X_test = apply_normalize(X_test, batch_size=batch_size, n_processes=n_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c369c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200  # Number of words in review to consider\n",
    "\n",
    "# Convert lists of words to vectors of numbers\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(maxlen)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sentences to be the same length\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "# Convert to tensors for Keras\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_test = tf.convert_to_tensor(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9839669",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de79d55",
   "metadata": {},
   "source": [
    "* Reference https://keras.io/examples/nlp/text_classification_with_transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e383c",
   "metadata": {},
   "source": [
    "##### Embedding Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01b20cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    \"\"\"Pre-transformer layer.\"\"\"\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        \n",
    "        # Token embedding\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        \n",
    "        # Position embedding\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b6a444",
   "metadata": {},
   "source": [
    "##### Transformer Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45cccaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    \"\"\"Transformer for embedding.\"\"\"\n",
    "    def __init__(self, embed_dim, num_heads, ff_dims, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        # Attention based on token and positional info\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        \n",
    "        # Feed-forward network with a layer for each number of neurons in ff_dims\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(dim, activation=\"relu\") for dim in ff_dims] + [layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        # Speed and regularization\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        # Calculate attention and get output\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25eea7b",
   "metadata": {},
   "source": [
    "##### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab5b8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "vocab_size = 20000   # Only consider the top 20k words\n",
    "embed_dim = 64       # Embedding size for each token\n",
    "num_heads = 8        # Number of attention heads\n",
    "ff_dims = (128, 64)  # Hidden layer sizes in feed forward network inside transformer\n",
    "\n",
    "# Input layer with max number of words\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "\n",
    "# Add embedding layer\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "# Add transformer\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dims)\n",
    "x = transformer_block(x)\n",
    "\n",
    "# Additional layers\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "# Output (5 possible categories for each star)\n",
    "outputs = layers.Dense(5, activation=\"softmax\")(x)\n",
    "\n",
    "# Create model\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58623f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 690ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.14825617, 0.1148558 , 0.22719812, 0.3003642 , 0.20932573],\n",
       "       [0.14536871, 0.11815089, 0.22080688, 0.2983354 , 0.21733806],\n",
       "       [0.14278641, 0.11228686, 0.22546056, 0.30506772, 0.21439849],\n",
       "       [0.14273828, 0.12180667, 0.2166766 , 0.29586586, 0.2229126 ],\n",
       "       [0.14392795, 0.11299901, 0.22679299, 0.3046798 , 0.21160023],\n",
       "       [0.14439009, 0.11663813, 0.22098571, 0.30024695, 0.2177391 ],\n",
       "       [0.13703337, 0.12003175, 0.2161892 , 0.2994284 , 0.22731726],\n",
       "       [0.14048219, 0.11871284, 0.22059964, 0.30455905, 0.21564622],\n",
       "       [0.14670691, 0.11607949, 0.22428201, 0.30092865, 0.2120029 ],\n",
       "       [0.14438182, 0.11383089, 0.2265254 , 0.30674917, 0.20851277]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example outputs (probabilities of each star rating)\n",
    "model.predict([X_train[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513f0e0",
   "metadata": {},
   "source": [
    "##### Compile and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ff48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0246e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9418 - accuracy: 0.6172 - val_loss: 0.9365 - val_accuracy: 0.6210\n",
      "Epoch 2/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9401 - accuracy: 0.6186 - val_loss: 0.9335 - val_accuracy: 0.6193\n",
      "Epoch 3/100\n",
      "15625/15625 [==============================] - 85s 5ms/step - loss: 0.9384 - accuracy: 0.6190 - val_loss: 0.9338 - val_accuracy: 0.6221\n",
      "Epoch 4/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9371 - accuracy: 0.6195 - val_loss: 0.9323 - val_accuracy: 0.6190\n",
      "Epoch 5/100\n",
      "15625/15625 [==============================] - 85s 5ms/step - loss: 0.9363 - accuracy: 0.6197 - val_loss: 0.9331 - val_accuracy: 0.6188\n",
      "Epoch 6/100\n",
      "15625/15625 [==============================] - 85s 5ms/step - loss: 0.9359 - accuracy: 0.6199 - val_loss: 0.9310 - val_accuracy: 0.6202\n",
      "Epoch 7/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9347 - accuracy: 0.6200 - val_loss: 0.9303 - val_accuracy: 0.6167\n",
      "Epoch 8/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9340 - accuracy: 0.6207 - val_loss: 0.9322 - val_accuracy: 0.6214\n",
      "Epoch 9/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9334 - accuracy: 0.6206 - val_loss: 0.9297 - val_accuracy: 0.6230\n",
      "Epoch 10/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9328 - accuracy: 0.6207 - val_loss: 0.9339 - val_accuracy: 0.6234\n",
      "Epoch 11/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9323 - accuracy: 0.6207 - val_loss: 0.9312 - val_accuracy: 0.6232\n",
      "Epoch 12/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9320 - accuracy: 0.6209 - val_loss: 0.9313 - val_accuracy: 0.6224\n",
      "Epoch 13/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9320 - accuracy: 0.6209 - val_loss: 0.9365 - val_accuracy: 0.6222\n",
      "Epoch 14/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9313 - accuracy: 0.6209 - val_loss: 0.9294 - val_accuracy: 0.6191\n",
      "Epoch 15/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9313 - accuracy: 0.6213 - val_loss: 0.9326 - val_accuracy: 0.6222\n",
      "Epoch 16/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9319 - accuracy: 0.6212 - val_loss: 0.9260 - val_accuracy: 0.6251\n",
      "Epoch 17/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9318 - accuracy: 0.6208 - val_loss: 0.9287 - val_accuracy: 0.6196\n",
      "Epoch 18/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9314 - accuracy: 0.6215 - val_loss: 0.9289 - val_accuracy: 0.6253\n",
      "Epoch 19/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9314 - accuracy: 0.6212 - val_loss: 0.9259 - val_accuracy: 0.6231\n",
      "Epoch 20/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9316 - accuracy: 0.6209 - val_loss: 0.9311 - val_accuracy: 0.6181\n",
      "Epoch 21/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9319 - accuracy: 0.6209 - val_loss: 0.9306 - val_accuracy: 0.6182\n",
      "Epoch 22/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9313 - accuracy: 0.6216 - val_loss: 0.9278 - val_accuracy: 0.6181\n",
      "Epoch 23/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9319 - accuracy: 0.6208 - val_loss: 0.9288 - val_accuracy: 0.6211\n",
      "Epoch 24/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9319 - accuracy: 0.6213 - val_loss: 0.9302 - val_accuracy: 0.6189\n",
      "Epoch 25/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9327 - accuracy: 0.6208 - val_loss: 0.9356 - val_accuracy: 0.6149\n",
      "Epoch 26/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9327 - accuracy: 0.6208 - val_loss: 0.9296 - val_accuracy: 0.6220\n",
      "Epoch 27/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9323 - accuracy: 0.6206 - val_loss: 0.9356 - val_accuracy: 0.6203\n",
      "Epoch 28/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9330 - accuracy: 0.6208 - val_loss: 0.9308 - val_accuracy: 0.6169\n",
      "Epoch 29/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9331 - accuracy: 0.6204 - val_loss: 0.9301 - val_accuracy: 0.6211\n",
      "Epoch 30/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9334 - accuracy: 0.6204 - val_loss: 0.9316 - val_accuracy: 0.6222\n",
      "Epoch 31/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9342 - accuracy: 0.6201 - val_loss: 0.9325 - val_accuracy: 0.6202\n",
      "Epoch 32/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9349 - accuracy: 0.6204 - val_loss: 0.9291 - val_accuracy: 0.6198\n",
      "Epoch 33/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9347 - accuracy: 0.6201 - val_loss: 0.9343 - val_accuracy: 0.6195\n",
      "Epoch 34/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9356 - accuracy: 0.6201 - val_loss: 0.9313 - val_accuracy: 0.6196\n",
      "Epoch 35/100\n",
      "15625/15625 [==============================] - 85s 5ms/step - loss: 0.9357 - accuracy: 0.6197 - val_loss: 0.9314 - val_accuracy: 0.6200\n",
      "Epoch 36/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9361 - accuracy: 0.6199 - val_loss: 0.9366 - val_accuracy: 0.6152\n",
      "Epoch 37/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9373 - accuracy: 0.6191 - val_loss: 0.9343 - val_accuracy: 0.6160\n",
      "Epoch 38/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9377 - accuracy: 0.6189 - val_loss: 0.9341 - val_accuracy: 0.6181\n",
      "Epoch 39/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9383 - accuracy: 0.6185 - val_loss: 0.9372 - val_accuracy: 0.6175\n",
      "Epoch 40/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9387 - accuracy: 0.6183 - val_loss: 0.9391 - val_accuracy: 0.6180\n",
      "Epoch 41/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9390 - accuracy: 0.6181 - val_loss: 0.9402 - val_accuracy: 0.6163\n",
      "Epoch 42/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9391 - accuracy: 0.6192 - val_loss: 0.9387 - val_accuracy: 0.6180\n",
      "Epoch 43/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9393 - accuracy: 0.6186 - val_loss: 0.9372 - val_accuracy: 0.6216\n",
      "Epoch 44/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9398 - accuracy: 0.6183 - val_loss: 0.9386 - val_accuracy: 0.6194\n",
      "Epoch 45/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9406 - accuracy: 0.6177 - val_loss: 0.9355 - val_accuracy: 0.6161\n",
      "Epoch 46/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9406 - accuracy: 0.6172 - val_loss: 0.9377 - val_accuracy: 0.6156\n",
      "Epoch 47/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9408 - accuracy: 0.6177 - val_loss: 0.9425 - val_accuracy: 0.6128\n",
      "Epoch 48/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9408 - accuracy: 0.6184 - val_loss: 0.9439 - val_accuracy: 0.6126\n",
      "Epoch 49/100\n",
      "15625/15625 [==============================] - 84s 5ms/step - loss: 0.9408 - accuracy: 0.6185 - val_loss: 0.9361 - val_accuracy: 0.6193\n",
      "Epoch 50/100\n",
      "15625/15625 [==============================] - 83s 5ms/step - loss: 0.9410 - accuracy: 0.6181 - val_loss: 0.9411 - val_accuracy: 0.6157\n",
      "Epoch 51/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9408 - accuracy: 0.6183 - val_loss: 0.9388 - val_accuracy: 0.6205\n",
      "Epoch 52/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9411 - accuracy: 0.6185 - val_loss: 0.9359 - val_accuracy: 0.6200\n",
      "Epoch 53/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9414 - accuracy: 0.6177 - val_loss: 0.9355 - val_accuracy: 0.6202\n",
      "Epoch 54/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9411 - accuracy: 0.6174 - val_loss: 0.9400 - val_accuracy: 0.6168\n",
      "Epoch 55/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9419 - accuracy: 0.6175 - val_loss: 0.9378 - val_accuracy: 0.6150\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9413 - accuracy: 0.6179 - val_loss: 0.9391 - val_accuracy: 0.6186\n",
      "Epoch 57/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9418 - accuracy: 0.6174 - val_loss: 0.9350 - val_accuracy: 0.6222\n",
      "Epoch 58/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9424 - accuracy: 0.6172 - val_loss: 0.9401 - val_accuracy: 0.6198\n",
      "Epoch 59/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9424 - accuracy: 0.6174 - val_loss: 0.9426 - val_accuracy: 0.6186\n",
      "Epoch 60/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9430 - accuracy: 0.6169 - val_loss: 0.9454 - val_accuracy: 0.6133\n",
      "Epoch 61/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9434 - accuracy: 0.6169 - val_loss: 0.9403 - val_accuracy: 0.6174\n",
      "Epoch 62/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9436 - accuracy: 0.6170 - val_loss: 0.9389 - val_accuracy: 0.6138\n",
      "Epoch 63/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9431 - accuracy: 0.6170 - val_loss: 0.9411 - val_accuracy: 0.6181\n",
      "Epoch 64/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9439 - accuracy: 0.6167 - val_loss: 0.9399 - val_accuracy: 0.6162\n",
      "Epoch 65/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9446 - accuracy: 0.6165 - val_loss: 0.9409 - val_accuracy: 0.6143\n",
      "Epoch 66/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9463 - accuracy: 0.6161 - val_loss: 0.9393 - val_accuracy: 0.6149\n",
      "Epoch 67/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9448 - accuracy: 0.6165 - val_loss: 0.9437 - val_accuracy: 0.6138\n",
      "Epoch 68/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9466 - accuracy: 0.6162 - val_loss: 0.9458 - val_accuracy: 0.6156\n",
      "Epoch 69/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9457 - accuracy: 0.6166 - val_loss: 0.9470 - val_accuracy: 0.6148\n",
      "Epoch 70/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9452 - accuracy: 0.6168 - val_loss: 0.9451 - val_accuracy: 0.6166\n",
      "Epoch 71/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9449 - accuracy: 0.6169 - val_loss: 0.9428 - val_accuracy: 0.6155\n",
      "Epoch 72/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9459 - accuracy: 0.6164 - val_loss: 0.9435 - val_accuracy: 0.6177\n",
      "Epoch 73/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9463 - accuracy: 0.6158 - val_loss: 0.9414 - val_accuracy: 0.6139\n",
      "Epoch 74/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9462 - accuracy: 0.6162 - val_loss: 0.9421 - val_accuracy: 0.6149\n",
      "Epoch 75/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9468 - accuracy: 0.6158 - val_loss: 0.9450 - val_accuracy: 0.6154\n",
      "Epoch 76/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9466 - accuracy: 0.6160 - val_loss: 0.9434 - val_accuracy: 0.6173\n",
      "Epoch 77/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9471 - accuracy: 0.6157 - val_loss: 0.9457 - val_accuracy: 0.6166\n",
      "Epoch 78/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9474 - accuracy: 0.6155 - val_loss: 0.9462 - val_accuracy: 0.6125\n",
      "Epoch 79/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9479 - accuracy: 0.6151 - val_loss: 0.9426 - val_accuracy: 0.6182\n",
      "Epoch 80/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9481 - accuracy: 0.6152 - val_loss: 0.9423 - val_accuracy: 0.6139\n",
      "Epoch 81/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9461 - accuracy: 0.6164 - val_loss: 0.9447 - val_accuracy: 0.6165\n",
      "Epoch 82/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9457 - accuracy: 0.6164 - val_loss: 0.9507 - val_accuracy: 0.6149\n",
      "Epoch 83/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9455 - accuracy: 0.6160 - val_loss: 0.9465 - val_accuracy: 0.6143\n",
      "Epoch 84/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9457 - accuracy: 0.6163 - val_loss: 0.9460 - val_accuracy: 0.6158\n",
      "Epoch 85/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9452 - accuracy: 0.6164 - val_loss: 0.9441 - val_accuracy: 0.6172\n",
      "Epoch 86/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9464 - accuracy: 0.6160 - val_loss: 0.9477 - val_accuracy: 0.6210\n",
      "Epoch 87/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9469 - accuracy: 0.6157 - val_loss: 0.9458 - val_accuracy: 0.6173\n",
      "Epoch 88/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9470 - accuracy: 0.6155 - val_loss: 0.9461 - val_accuracy: 0.6155\n",
      "Epoch 89/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9463 - accuracy: 0.6153 - val_loss: 0.9464 - val_accuracy: 0.6099\n",
      "Epoch 90/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9471 - accuracy: 0.6156 - val_loss: 0.9445 - val_accuracy: 0.6156\n",
      "Epoch 91/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9479 - accuracy: 0.6155 - val_loss: 0.9462 - val_accuracy: 0.6176\n",
      "Epoch 92/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9476 - accuracy: 0.6158 - val_loss: 0.9450 - val_accuracy: 0.6137\n",
      "Epoch 93/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9476 - accuracy: 0.6155 - val_loss: 0.9463 - val_accuracy: 0.6148\n",
      "Epoch 94/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9474 - accuracy: 0.6150 - val_loss: 0.9496 - val_accuracy: 0.6144\n",
      "Epoch 95/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9468 - accuracy: 0.6158 - val_loss: 0.9480 - val_accuracy: 0.6145\n",
      "Epoch 96/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9473 - accuracy: 0.6156 - val_loss: 0.9491 - val_accuracy: 0.6131\n",
      "Epoch 97/100\n",
      "15625/15625 [==============================] - 81s 5ms/step - loss: 0.9469 - accuracy: 0.6154 - val_loss: 0.9482 - val_accuracy: 0.6207\n",
      "Epoch 98/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9472 - accuracy: 0.6154 - val_loss: 0.9518 - val_accuracy: 0.6201\n",
      "Epoch 99/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9472 - accuracy: 0.6151 - val_loss: 0.9528 - val_accuracy: 0.6140\n",
      "Epoch 100/100\n",
      "15625/15625 [==============================] - 82s 5ms/step - loss: 0.9477 - accuracy: 0.6148 - val_loss: 0.9489 - val_accuracy: 0.6146\n",
      "CPU times: total: 2h 36min 27s\n",
      "Wall time: 2h 17min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train model\n",
    "epochs = 50\n",
    "\n",
    "# Early stopping \n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint_path = \"model_checkpoints/proto.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "create_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, create_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bf9d83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = history.history\n",
    "acc, val_acc = hist[\"accuracy\"], hist[\"val_accuracy\"]\n",
    "\n",
    "plt.figure(figsize=(5, 4), dpi=100)\n",
    "plt.plot(acc, label=\"acc\")\n",
    "plt.plot(val_acc, label=\"val_acc\")\n",
    "plt.axhline(0.2, color=\"red\", label=\"base\")\n",
    "plt.xlim(0, epochs - 1)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.grid(axis=\"y\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f989e506",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4aab1fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Get probabilities per class\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f8ece44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get star predictions and negative/positive predictions\n",
    "y_pred_multi = tf.argmax(y_pred, axis=1)\n",
    "y_pred_binary = y_pred_multi >= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "458f93b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-class accuracy: 0.6146\n",
      "(compare to 0.2)\n"
     ]
    }
   ],
   "source": [
    "print(\"multi-class accuracy: \" + str((y_pred_multi == y_test).numpy().sum() / len(y_test)))\n",
    "print(\"(compare to 0.2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6526ece6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary accuracy: 0.845\n",
      "(compare to 0.5)\n"
     ]
    }
   ],
   "source": [
    "print(\"binary accuracy: \" + str((y_pred_binary == (y_test >= 3)).numpy().sum() / len(y_test)))\n",
    "print(\"(compare to 0.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d46ed4",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86279fcb",
   "metadata": {},
   "source": [
    "> While a preprocessing pipeline and classifier have been successfully established and employed, the results could probably be improved. ~61% accuracy for 5-star ratings and ~84% accuracy for binary ratings may be improved by using the rest of our data, further experimentation with architecture, and, perhaps most importantly, additional preprocessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu]",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
